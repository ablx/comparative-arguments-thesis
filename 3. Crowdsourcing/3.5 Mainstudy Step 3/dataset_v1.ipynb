{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_confidence(row, agg_data):\n",
    "    data = agg_data[agg_data['id'] == row['id']]\n",
    "    return data.iloc[0]['label:confidence']\n",
    "\n",
    "\n",
    "def load_dataset(folder):\n",
    "    def add_fields(df,iteration):\n",
    "        df['iteration'] = iteration\n",
    "        df['domain'] = folder[0].split('-')[0]\n",
    "        return df\n",
    "         \n",
    "    agg_list = []\n",
    "    full_list = []\n",
    "    test_list = []\n",
    "    for f in folder:\n",
    "\n",
    "        iteration = 2 if 'it3' in f else 1\n",
    "        agg = pd.read_csv('{}/agg.csv'.format(f))\n",
    "        agg = add_fields(agg,iteration)\n",
    "        agg['raw_text'] = agg.apply(\n",
    "        lambda row: BeautifulSoup(row['text_html'], \"lxml\").text.replace(':[OBJECT_A]', '').replace(':[OBJECT_B]', ''),\n",
    "        axis=1)\n",
    "        agg_list.append(agg)\n",
    "        \n",
    "        \n",
    "        full = pd.read_csv('{}/full.csv'.format(f))\n",
    "        full = add_fields(full,iteration)\n",
    "        full_list.append(full)\n",
    "        \n",
    "        test = pd.read_csv('{}/test.csv'.format(f))\n",
    "        test = add_fields(test,iteration)\n",
    "        test_list.append(test)\n",
    "    return pd.concat(agg_list), pd.concat(full_list), pd.concat(test_list)\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbt_agg, jbt_full, jbt_test = load_dataset(['jbt-data', 'jbt-data-it2','jbt-data-it3'])\n",
    "compsci_agg, compsci_full, compsci_test = load_dataset(['compsci-data', 'compsci-data-it2', 'compsci-data-it3'])\n",
    "brands_agg, brands_full, brands_test = load_dataset(['brands-data-100', 'brands-data-400', 'brands-data-it2', 'brands-data-it3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['id','domain', 'object_a', 'object_b', 'sentence', 'it_1_confidence', 'it_2_confidence', \n",
    "           'better_count', 'worse_count','none_count', 'most_frequent_label', 'most_frequent_count', \n",
    "           'it_1_judgments', 'it_2_judgments', 'sentence_html']\n",
    "\n",
    "\n",
    "def add_columns(agg,full):\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for sid in full['id'].unique():\n",
    "        better_count = 0\n",
    "        better_trust = 0\n",
    "        worse_count = 0\n",
    "        worse_trust = 0\n",
    "        none_count = 0\n",
    "        none_trust = 0\n",
    "        it_1_judgments = 0\n",
    "        it_2_judgments = 0\n",
    "        most_frequent = ''\n",
    "        f_subset = full[full['id'] == sid]\n",
    "        for i, f_row in f_subset.iterrows():\n",
    "            label = f_row['label']\n",
    "            _iteration = f_row['iteration']\n",
    "            if _iteration == 1:\n",
    "                it_1_judgments +=1\n",
    "            else:\n",
    "                it_2_judgments += 1\n",
    "                \n",
    "            if 'BETTER' == label:\n",
    "                better_count +=1\n",
    "                better_trust += f_row['_trust']\n",
    "            elif 'WORSE' == label:\n",
    "                worse_count += 1\n",
    "                worse_trust += f_row['_trust']\n",
    "            else:\n",
    "                none_count +=1\n",
    "                none_trust += f_row['_trust']\n",
    "        winner = sorted([(better_trust, better_count, 'BETTER'), (worse_trust, worse_count, 'WORSE'),\n",
    "                         (none_trust, none_count, 'NONE')],reverse=True)\n",
    "        most_frequent_label = winner[0][2]\n",
    "        most_frequent_count = winner[0][1]\n",
    "        \n",
    "        a_it1 = agg[(agg['id'] == sid) & (agg['iteration'] == 1)]\n",
    "        a_it2 = agg[(agg['id'] == sid) & (agg['iteration'] == 2)]\n",
    "        \n",
    "\n",
    "        if len(a_it1) == 1 and len(a_it2) == 1:\n",
    "            content = [sid,a_it1.iloc[0]['domain'], a_it1.iloc[0]['a'], a_it1.iloc[0]['b'],a_it1.iloc[0]['raw_text'],\n",
    "                       a_it1.iloc[0]['label:confidence'],a_it2.iloc[0]['label:confidence'],\n",
    "                       better_count,worse_count,none_count,most_frequent_label,most_frequent_count,it_1_judgments,it_2_judgments,a_it1.iloc[0]['text_html']]\n",
    "            df.loc[len(df)] =content\n",
    "    \n",
    "    df['judgments'] = df['it_1_judgments'] + df['it_2_judgments']\n",
    "    it1_c = df['it_1_confidence'] * (df['it_1_judgments']/ df['judgments'])\n",
    "    it2_c = df['it_2_confidence'] * (df['it_2_judgments']/ df['judgments'])\n",
    "    df['confidence'] = it1_c+it2_c\n",
    "    \n",
    "    df['most_frequent_percentage'] = df['most_frequent_count'] / df['judgments']\n",
    "    numeric_cols =['confidence', 'most_frequent_count', 'most_frequent_percentage','judgments']\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compsci = add_columns(compsci_agg,compsci_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = add_columns(brands_agg,brands_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbt = add_columns(jbt_agg,jbt_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi = pd.concat([compsci,brands,jbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All rows: {} Unique: {}'.format(len(combi), len(combi['id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"most_frequent_label\", data=combi);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_i, test_i = train_test_split(combi,stratify=combi['most_frequent_label'], test_size=0.2,random_state=42)\n",
    "print('{} {} {}'.format(len(train_i), len(test_i), (len(train_i)+ len(test_i))))\n",
    "combi.to_csv('all-data.csv',index=False)\n",
    "train_i.to_csv('data.csv',index=False)\n",
    "test_i.to_csv('held-out-data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi[combi['most_frequent_percentage'] == 0.5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
