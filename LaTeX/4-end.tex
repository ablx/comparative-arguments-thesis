\chapter{Conclusion}


\begin{appendices}
\chapter{Detailed Classification Results}
The following shows the classification results and the confusion matrix for each of the five folds per feature.

\section{Three-class scenario}
\begin{verbatim}

== Bag-Of-Words

             precision    recall  f1-score   support

     BETTER       0.77      0.79      0.78       219
      WORSE       0.60      0.31      0.41        95
       NONE       0.90      0.95      0.92       839

avg / total       0.85      0.86      0.85      1153

[[172   5  42]
 [ 22  29  44]
 [ 30  14 795]]
 
             precision    recall  f1-score   support

     BETTER       0.79      0.78      0.78       218
      WORSE       0.54      0.34      0.42        95
       NONE       0.90      0.95      0.92       839

avg / total       0.85      0.86      0.86      1152

[[169  14  35]
 [ 12  32  51]
 [ 32  13 794]]
 
             precision    recall  f1-score   support

     BETTER       0.75      0.74      0.75       218
      WORSE       0.59      0.24      0.34        95
       NONE       0.89      0.95      0.92       839

avg / total       0.84      0.85      0.84      1152

[[162   6  50]
 [ 20  23  52]
 [ 33  10 796]]
 
             precision    recall  f1-score   support

     BETTER       0.81      0.71      0.76       218
      WORSE       0.64      0.37      0.47        95
       NONE       0.89      0.96      0.92       839

avg / total       0.85      0.86      0.85      1152

[[155   8  55]
 [ 11  35  49]
 [ 25  12 802]]
 
             precision    recall  f1-score   support

     BETTER       0.80      0.78      0.79       218
      WORSE       0.52      0.35      0.42        94
       NONE       0.90      0.94      0.92       838

avg / total       0.85      0.86      0.85      1150

[[169  11  38]
 [ 11  33  50]
 [ 32  19 787]]

(Summed up confusion matrix)
[[ 827   44  220]
 [  76  152  246]
 [ 152   68 3974]]



== InferSent

             precision    recall  f1-score   support

     BETTER       0.73      0.79      0.76       219
      WORSE       0.69      0.28      0.40        95
       NONE       0.91      0.95      0.93       839

avg / total       0.85      0.86      0.85      1153

[[172   6  41]
 [ 26  27  42]
 [ 38   6 795]]
 
             precision    recall  f1-score   support

     BETTER       0.78      0.74      0.76       218
      WORSE       0.51      0.28      0.36        95
       NONE       0.89      0.95      0.92       839

avg / total       0.84      0.86      0.84      1152

[[162  13  43]
 [ 16  27  52]
 [ 30  13 796]]
 
             precision    recall  f1-score   support

     BETTER       0.76      0.71      0.73       218
      WORSE       0.65      0.39      0.49        95
       NONE       0.89      0.95      0.92       839

avg / total       0.85      0.86      0.85      1152

[[155  12  51]
 [ 14  37  44]
 [ 36   8 795]]
 
 
 
             precision    recall  f1-score   support

     BETTER       0.77      0.69      0.73       218
      WORSE       0.60      0.34      0.43        95
       NONE       0.89      0.96      0.92       839

avg / total       0.84      0.86      0.84      1152

[[151  11  56]
 [ 17  32  46]
 [ 27  10 802]]
 
             precision    recall  f1-score   support

     BETTER       0.78      0.76      0.77       218
      WORSE       0.62      0.35      0.45        94
       NONE       0.90      0.95      0.93       838

avg / total       0.86      0.87      0.86      1150

[[166  10  42]
 [ 17  33  44]
 [ 30  10 798]]
 
(Summed up confusion matrix)
[[ 806   52  233]
 [  90  156  228]
 [ 161   47 3986]]


== Word Embedding

             precision    recall  f1-score   support

     BETTER       0.70      0.74      0.72       219
      WORSE       0.55      0.19      0.28        95
       NONE       0.89      0.94      0.92       839

avg / total       0.83      0.84      0.83      1153

[[162   4  53]
 [ 35  18  42]
 [ 36  11 792]]
 
             precision    recall  f1-score   support

     BETTER       0.69      0.72      0.70       218
      WORSE       0.45      0.15      0.22        95
       NONE       0.89      0.95      0.92       839

avg / total       0.81      0.84      0.82      1152

[[156   8  54]
 [ 36  14  45]
 [ 35   9 795]]
 
             precision    recall  f1-score   support

     BETTER       0.69      0.72      0.71       218
      WORSE       0.43      0.14      0.21        95
       NONE       0.88      0.94      0.91       839

avg / total       0.81      0.83      0.82      1152

[[158   7  53]
 [ 31  13  51]
 [ 39  10 790]]
 
             precision    recall  f1-score   support

     BETTER       0.69      0.63      0.66       218
      WORSE       0.39      0.14      0.20        95
       NONE       0.87      0.95      0.91       839

avg / total       0.80      0.82      0.80      1152

[[137   9  72]
 [ 33  13  49]
 [ 29  11 799]]
 
             precision    recall  f1-score   support

     BETTER       0.70      0.71      0.71       218
      WORSE       0.52      0.17      0.26        94
       NONE       0.88      0.95      0.91       838

avg / total       0.82      0.84      0.82      1150

[[155   7  56]
 [ 30  16  48]
 [ 36   8 794]]
 
(Summed up confusion matrix)

[[ 768   35  288]
 [ 165   74  235]
 [ 175   49 3970]]



== POS n-grams

             precision    recall  f1-score   support

     BETTER       0.60      0.68      0.64       219
      WORSE       0.28      0.11      0.15        95
       NONE       0.88      0.90      0.89       839

avg / total       0.77      0.80      0.78      1153

[[150   8  61]
 [ 39  10  46]
 [ 62  18 759]]
 
             precision    recall  f1-score   support

     BETTER       0.64      0.62      0.63       218
      WORSE       0.38      0.08      0.14        95
       NONE       0.86      0.95      0.90       839

avg / total       0.78      0.81      0.79      1152

[[136   8  74]
 [ 36   8  51]
 [ 40   5 794]]
 
             precision    recall  f1-score   support

     BETTER       0.57      0.63      0.60       218
      WORSE       0.23      0.07      0.11        95
       NONE       0.86      0.90      0.88       839

avg / total       0.75      0.78      0.76      1152

[[137   8  73]
 [ 36   7  52]
 [ 67  15 757]]
 
             precision    recall  f1-score   support

     BETTER       0.56      0.54      0.55       218
      WORSE       0.30      0.11      0.16        95
       NONE       0.85      0.92      0.89       839

avg / total       0.75      0.78      0.76      1152

[[117  11  90]
 [ 40  10  45]
 [ 51  12 776]]
 
             precision    recall  f1-score   support

     BETTER       0.59      0.63      0.61       218
      WORSE       0.32      0.12      0.17        94
       NONE       0.87      0.92      0.90       838

avg / total       0.77      0.80      0.78      1150

[[137  13  68]
 [ 40  11  43]
 [ 56  10 772]]
 
(Summed up confusion matrix)
[[ 677   48  366]
 [ 191   46  237]
 [ 276   60 3858]]


== Contains JJR

             precision    recall  f1-score   support

     BETTER       0.56      0.65      0.60       219
      WORSE       0.00      0.00      0.00        95
       NONE       0.87      0.93      0.90       839

avg / total       0.74      0.80      0.77      1153

[[143   0  76]
 [ 53   0  42]
 [ 58   0 781]]
 
             precision    recall  f1-score   support

     BETTER       0.57      0.61      0.59       218
      WORSE       0.00      0.00      0.00        95
       NONE       0.85      0.93      0.89       839

avg / total       0.73      0.79      0.76      1152

[[134   0  84]
 [ 43   0  52]
 [ 58   0 781]]
 
             precision    recall  f1-score   support

     BETTER       0.55      0.54      0.54       218
      WORSE       0.00      0.00      0.00        95
       NONE       0.83      0.93      0.87       839

avg / total       0.71      0.78      0.74      1152

[[117   0 101]
 [ 35   0  60]
 [ 62   0 777]]
             precision    recall  f1-score   support

     BETTER       0.58      0.56      0.57       218
      WORSE       0.00      0.00      0.00        95
       NONE       0.84      0.94      0.89       839

avg / total       0.72      0.79      0.76      1152

[[122   0  96]
 [ 42   0  53]
 [ 48   0 791]]
 
             precision    recall  f1-score   support

     BETTER       0.56      0.62      0.59       218
      WORSE       0.00      0.00      0.00        94
       NONE       0.85      0.92      0.88       838

avg / total       0.73      0.79      0.76      1150

[[136   0  82]
 [ 40   0  54]
 [ 67   0 771]]
 
(Summed up confusion matrix)

[[ 652    0  439]
 [ 213    0  261]
 [ 293    0 3901]]


 
\end{verbatim}
\section{Binary scenario}
\begin{verbatim}
== Bag-Of-Words

             precision    recall  f1-score   support

        ARG       0.81      0.73      0.77       313
       NONE       0.90      0.94      0.92       839

avg / total       0.88      0.88      0.88      1152

[[227  86]
 [ 52 787]]
             precision    recall  f1-score   support

        ARG       0.81      0.73      0.77       313
       NONE       0.90      0.94      0.92       839

avg / total       0.88      0.88      0.88      1152

[[228  85]
 [ 52 787]]
             precision    recall  f1-score   support

        ARG       0.85      0.73      0.79       313
       NONE       0.91      0.95      0.93       839

avg / total       0.89      0.89      0.89      1152

[[230  83]
 [ 40 799]]
             precision    recall  f1-score   support

        ARG       0.79      0.72      0.76       313
       NONE       0.90      0.93      0.91       839

avg / total       0.87      0.87      0.87      1152

[[226  87]
 [ 59 780]]
             precision    recall  f1-score   support

        ARG       0.80      0.72      0.76       313
       NONE       0.90      0.93      0.91       838

avg / total       0.87      0.87      0.87      1151

[[226  87]
 [ 58 780]]

(Summed up confusion matrix)
[[1137  428]
 [ 261 3933]]


== InferSent

             precision    recall  f1-score   support

        ARG       0.79      0.74      0.76       313
       NONE       0.90      0.93      0.92       839

avg / total       0.87      0.88      0.88      1152

[[231  82]
 [ 60 779]]
             precision    recall  f1-score   support

        ARG       0.81      0.80      0.81       313
       NONE       0.93      0.93      0.93       839

avg / total       0.89      0.89      0.89      1152

[[251  62]
 [ 59 780]]
             precision    recall  f1-score   support

        ARG       0.83      0.75      0.79       313
       NONE       0.91      0.94      0.93       839

avg / total       0.89      0.89      0.89      1152

[[235  78]
 [ 48 791]]
             precision    recall  f1-score   support

        ARG       0.81      0.80      0.80       313
       NONE       0.93      0.93      0.93       839

avg / total       0.89      0.89      0.89      1152

[[250  63]
 [ 59 780]]
             precision    recall  f1-score   support

        ARG       0.80      0.76      0.78       313
       NONE       0.91      0.93      0.92       838

avg / total       0.88      0.88      0.88      1151

[[237  76]
 [ 58 780]]
 
(Summed up confusion matrix)
[[1204  361]
 [ 284 3910]]


== Word Embedding

             precision    recall  f1-score   support

        ARG       0.78      0.72      0.74       313
       NONE       0.90      0.92      0.91       839

avg / total       0.86      0.87      0.86      1152

[[224  89]
 [ 65 774]]
             precision    recall  f1-score   support

        ARG       0.80      0.77      0.78       313
       NONE       0.92      0.93      0.92       839

avg / total       0.88      0.88      0.88      1152

[[241  72]
 [ 62 777]]
             precision    recall  f1-score   support

        ARG       0.80      0.73      0.76       313
       NONE       0.90      0.93      0.92       839

avg / total       0.88      0.88      0.88      1152

[[229  84]
 [ 57 782]]
             precision    recall  f1-score   support

        ARG       0.78      0.76      0.77       313
       NONE       0.91      0.92      0.92       839

avg / total       0.88      0.88      0.88      1152

[[237  76]
 [ 65 774]]
             precision    recall  f1-score   support

        ARG       0.76      0.72      0.74       313
       NONE       0.90      0.92      0.91       838

avg / total       0.86      0.86      0.86      1151

[[224  89]
 [ 69 769]]
 
(Summed up confusion matrix)
[[1155  410]
 [ 318 3876]]


== POS n-grams

             precision    recall  f1-score   support

        ARG       0.70      0.69      0.70       313
       NONE       0.89      0.89      0.89       839

avg / total       0.84      0.84      0.84      1152

[[216  97]
 [ 92 747]]
             precision    recall  f1-score   support

        ARG       0.71      0.68      0.69       313
       NONE       0.88      0.90      0.89       839

avg / total       0.84      0.84      0.84      1152

[[213 100]
 [ 87 752]]
             precision    recall  f1-score   support

        ARG       0.74      0.70      0.72       313
       NONE       0.89      0.91      0.90       839

avg / total       0.85      0.85      0.85      1152

[[218  95]
 [ 75 764]]
             precision    recall  f1-score   support

        ARG       0.75      0.67      0.71       313
       NONE       0.88      0.92      0.90       839

avg / total       0.85      0.85      0.85      1152

[[209 104]
 [ 69 770]]
             precision    recall  f1-score   support

        ARG       0.72      0.68      0.70       313
       NONE       0.88      0.90      0.89       838

avg / total       0.84      0.84      0.84      1151

[[214  99]
 [ 85 753]]

(Summed up confusion matrix)
[[1070  495]
 [ 408 3786]]


== Contains JJR

             precision    recall  f1-score   support

        ARG       0.75      0.53      0.62       313
       NONE       0.84      0.93      0.89       839

avg / total       0.82      0.82      0.81      1152

[[165 148]
 [ 55 784]]
             precision    recall  f1-score   support

        ARG       0.72      0.56      0.63       313
       NONE       0.85      0.92      0.88       839

avg / total       0.81      0.82      0.81      1152

[[175 138]
 [ 69 770]]
             precision    recall  f1-score   support

        ARG       0.77      0.58      0.66       313
       NONE       0.86      0.94      0.90       839

avg / total       0.83      0.84      0.83      1152

[[182 131]
 [ 53 786]]
             precision    recall  f1-score   support

        ARG       0.76      0.58      0.65       313
       NONE       0.85      0.93      0.89       839

avg / total       0.83      0.84      0.83      1152

[[180 133]
 [ 57 782]]
             precision    recall  f1-score   support

        ARG       0.73      0.52      0.61       313
       NONE       0.84      0.93      0.88       838

avg / total       0.81      0.82      0.81      1151

[[163 150]
 [ 59 779]]
 
(Summed up confusion matrix)
[[ 865  700]
 [ 293 3901]]

\end{verbatim}

\chapter{Crowdsourcing Campaign Ratings}
\end{appendices}