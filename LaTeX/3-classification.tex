\chapter{Classification of Comparative Sentences}
\section{Experiments}
The data collected from the crowdsourcing task was used as training data for classification problems. In the first problem, the machine learning algorithms were trained so that they were able to assign one of the three original classes (see table X) to the data. The second problem is a simplification of the first one as it is designed as a binary classification problem. The classes \texttt{BETTER} and \texttt{WORSE}were merged into the class \texttt{ARG}.

For all problems, three classification algorithms were used: L2 regulised Logistic Regression, and eXtreme Gradient Boosting. 

Logistic Regression is a simple, frequently used classification algorithm, for instance, it was used in \cite{Daxenberger2017What-is-the-Ess} with great success. The sklearn implementation (\cite{scikit-learn}) was used.

Extreme Gradient Boosting ...


The data was split into a train (5937 examples; 4270 \texttt{NONE}, 1158 \texttt{BETTER} and 509 \texttt{WORSE}) and a dev (x examples) set. The dev set stayed untouched until the final evaluation presented in section \ref{sec:final}. During the development, the experiments were evaluated using stratified k-fold cross-validation where k is five. The evaluation was done with the sklearn implementation. The weighted F1 score is used as the metric. In the following, the worst, best and median folds are shown.

\section{Baseline}
As described in section \ref{sec:argmine}, there is no task which is similar enough to this one which could be used as a baseline. Thus, two baselines using the obtained data were created. The first baseline, shown in table \ref{tbl:majorityclass}, assigns all sentences to the class \texttt{NONE}.



    \begin{table}[h]
\centering
\caption{ Majority Class Baseline }
\label{tbl:majority_class_baseline }
\begin{tabular}{@{}lccccccccc@{}}
\toprule
      & \multicolumn{3}{c}{Worst} & \multicolumn{3}{c}{Average} & \multicolumn{3}{c}{Best}  \\ \midrule
                 & Precision  & Recall & F1   & Precision  & Recall  & F1    & Precision & Recall & F1   \\ \toprule

    
\texttt{BETTER}	 & 0.00	 & 0.00	 & 0.00	 &0.00	 & 0.00	 & 0.00	 &0.00	 & 0.00	 & 0.00	 \\ 
\texttt{WORSE}	 & 0.00	 & 0.00	 & 0.00	 &0.00	 & 0.00	 & 0.00	 &0.00	 & 0.00	 & 0.00	 \\ 
\texttt{NONE}	 & 0.72	 & 1.00	 & 0.84	 &0.72	 & 1.00	 & 0.84	 &0.72	 & 1.00	 & 0.84	 \\ \midrule 
average	 & 0.52	 & 0.72	 & 0.60	 &0.52	 & 0.72	 & \textbf{0.60}	 &0.52	 & 0.72	 & 0.60	 \\ \bottomrule

    \end{tabular}
\end{table}


The second baseline, shown in table \ref{tbl:ngrambs} used LogisticRegression and for classification and an unigram model (as described in \ref{sec:ngram}). The unigram model is build using the vocabulary of all test sentences in the given fold.

    \begin{table}[h]
\centering
\caption{ cap }
\label{tbl:cap }
\begin{tabular}{@{}lccccccccc@{}}
\toprule
      & \multicolumn{3}{c}{Worst} & \multicolumn{3}{c}{Average} & \multicolumn{3}{c}{Best}  \\ \midrule
                 & Precision  & Recall & F1   & Precision  & Recall  & F1    & Precision & Recall & F1   \\ \toprule

    
\texttt{BETTER}	 & 0.44	 & 0.49	 & 0.46	 &0.50	 & 0.51	 & 0.51	 &0.52	 & 0.58	 & 0.55	 \\ 
\texttt{WORSE}	 & 0.33	 & 0.19	 & 0.24	 &0.25	 & 0.15	 & 0.18	 &0.28	 & 0.18	 & 0.22	 \\ 
\texttt{NONE}	 & 0.82	 & 0.84	 & 0.83	 &0.83	 & 0.87	 & 0.85	 &0.83	 & 0.85	 & 0.84	 \\ \midrule 
average	 & 0.70	 & 0.72	 & 0.71	 &0.72	 & 0.74	 & 0.72	 &0.73	 & 0.74	 & 0.73	 \\ \bottomrule

    \end{tabular}
\end{table}




\section{Features}
\subsection{N-Gram Models}
\label{sec:ngram}

\subsection{Sentence Embeddings}
\subsection{Other Features}
% n-grams
% sentence embeddings
% POS JJR

\section{Final results}
\label{sec:final}

\section{Discussion}