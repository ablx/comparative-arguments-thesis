{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import *\n",
    "from IPython.display import display, HTML, IFrame\n",
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from bs4 import BeautifulSoup\n",
    "set_matplotlib_formats('png','pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "brands = ['brands-data-100', 'brands-data-400', 'brands-data-it2', 'brands-data-it3']\n",
    "compsci = ['compsci-data', 'compsci-data-it2', 'compsci-data-it3']\n",
    "jbt = ['jbt-data', 'jbt-data-it2']\n",
    "folder = compsci\n",
    "MERGE_OTHER = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### compsci-data\n",
      "Agg 750\n",
      "Full 2408\n",
      "Test 53\n",
      "### compsci-data-it2\n",
      "Agg 1719\n",
      "Full 5181\n",
      "Test 56\n",
      "### compsci-data-it3\n",
      "Agg 2425\n",
      "Full 4900\n",
      "Test 58\n"
     ]
    }
   ],
   "source": [
    "agg_list = []\n",
    "full_list = []\n",
    "test_list = []\n",
    "for f in folder:\n",
    "    iteration = 2 if 'it3' in f else 1\n",
    "    print('### {}'.format(f))\n",
    "    agg =  pd.read_csv('{}/agg.csv'.format(f))\n",
    "    agg['type'] = f.split('-')[0]\n",
    "    agg.set_index('id')\n",
    "\n",
    "    agg['iteration'] = iteration\n",
    "    agg['source_file'] = f\n",
    "    if iteration == 1:\n",
    "        agg = agg.rename(columns={'label:confidence' : 'iteration_1_confidence'})\n",
    "    else:\n",
    "        agg = agg.rename(columns={'label:confidence' : 'iteration_2_confidence'}) \n",
    "    agg_list.append(agg)    \n",
    "    \n",
    "    print('Agg {}'.format(len(agg)))\n",
    "   \n",
    "    full = pd.read_csv('{}/full.csv'.format(f))\n",
    "    full['type'] = f.split('-')[0]\n",
    "    full['iteration'] = iteration\n",
    "    full['source_file'] = f\n",
    "    full.set_index('id')\n",
    "    full_list.append( full)\n",
    "    print('Full {}'.format(len(full)))\n",
    "    \n",
    "    test = pd.read_csv('{}/test.csv'.format(f))\n",
    "\n",
    "    test = test[test['_hidden'] == False]\n",
    "    test['type'] = f.split('-')[0]\n",
    "    test.set_index('id')\n",
    "    test['iteration'] = iteration\n",
    "    test['source_file'] = f\n",
    "    print('Test {}'.format(len(test)))\n",
    "    test_list.append (test)\n",
    "    \n",
    "aggregated = pd.concat(agg_list)\n",
    "if MERGE_OTHER:\n",
    "    aggregated['label'] = aggregated.apply(lambda row: row['label'] if row['label'] != 'OTHER' else 'NONE', axis=1)\n",
    "    full['label'] = full.apply(lambda row: row['label'] if row['label'] != 'OTHER' else 'NONE', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "full = pd.concat(full_list)\n",
    "test_questions = pd.concat(test_list)\n",
    "\n",
    "aggregated = aggregated[aggregated['_unit_state'] == 'finalized']\n",
    "aggregated['raw_text'] = aggregated.apply(\n",
    "        lambda row: BeautifulSoup(row['text_html'], \"lxml\").text.replace(':[OBJECT_A]', '').replace(':[OBJECT_B]', ''),\n",
    "        axis=1)\n",
    "\n",
    "\n",
    "def print_info(data):\n",
    "    avg = pd.merge(data, full, suffixes=['_l', '_r'], on=['id'], how='left')[['id', 'text_readable_r', 'label:confidence', 'label_l', '_golden', 'label_r', '_trust','a','b']].sort_values(['label:confidence', 'label_l' ,'id'])\n",
    "    renamed_avg = avg.rename(columns={'label_l' : 'assigned_by_crowdflower', 'label_r' : 'proposed_by_annotator'})\n",
    "    renamed_avg\n",
    "    return renamed_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_golden</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>a</th>\n",
       "      <th>also_acceptable</th>\n",
       "      <th>b</th>\n",
       "      <th>expected_label</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>label</th>\n",
       "      <th>label_gold</th>\n",
       "      <th>label_gold_reason</th>\n",
       "      <th>marker</th>\n",
       "      <th>orig__golden</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>source_file</th>\n",
       "      <th>text_html</th>\n",
       "      <th>text_readable</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>1/11/2018 13:03:12</td>\n",
       "      <td>3</td>\n",
       "      <td>1534176833</td>\n",
       "      <td>finalized</td>\n",
       "      <td>USB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bluetooth</td>\n",
       "      <td>W</td>\n",
       "      <td>L1868520095</td>\n",
       "      <td>...</td>\n",
       "      <td>WORSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Of course you also have the option of the USB,...</td>\n",
       "      <td>compsci-data</td>\n",
       "      <td>Of course you also have the option of the &lt;spa...</td>\n",
       "      <td>Of course you also have the option of the *USB...</td>\n",
       "      <td>compsci</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _golden   _last_judgment_at  _trusted_judgments    _unit_id _unit_state  \\\n",
       "3    False  1/11/2018 13:03:12                   3  1534176833   finalized   \n",
       "\n",
       "     a also_acceptable          b expected_label           id   ...     label  \\\n",
       "3  USB             NaN  Bluetooth              W  L1868520095   ...     WORSE   \n",
       "\n",
       "   label_gold  label_gold_reason marker  orig__golden  \\\n",
       "3         NaN                NaN   True           NaN   \n",
       "\n",
       "                                            raw_text   source_file  \\\n",
       "3  Of course you also have the option of the USB,...  compsci-data   \n",
       "\n",
       "                                           text_html  \\\n",
       "3  Of course you also have the option of the <spa...   \n",
       "\n",
       "                                       text_readable     type  \n",
       "3  Of course you also have the option of the *USB...  compsci  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = aggregated.sort_values('_trusted_judgments',ascending=False)\n",
    "print(len(a[a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-16 19:49:15.462438\n",
      "2469 2465\n",
      "L1868520095\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5e12e17b60f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mit1_judgments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_trusted_judgments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mit1_confidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iteration_1_confidence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mit2_judgments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_trusted_judgments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mit2_confidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iteration_1_confidence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/comparative-arguments/ve/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/comparative-arguments/ve/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1829\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1830\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_valid_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/comparative-arguments/ve/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_is_valid_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1713\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1714\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "print('{} {}'.format(len(full['id'].unique()),len(aggregated['id'].unique())))\n",
    "dataset = pd.DataFrame(columns=['id', 'raw_text', 'better_count', 'worse_count', 'none_count', 'most_frequent_class',\n",
    "                                'most_frequent_class_percentage','total_judgments', \n",
    "                                'it1_judgments', 'it2_judgments', 'it1_confidence', 'it2_confidence', 'confidence'])\n",
    "\n",
    "for i, row in full.iterrows():\n",
    "    sid = row['id']\n",
    "    raw_text = row['raw_text']\n",
    "    \n",
    "    it1 = aggregated[(aggregated['id'] == sid) &(aggregated['iteration'] == 1)]\n",
    "    it2 = aggregated[(aggregated['id'] == sid) &(aggregated['iteration'] == 2)]\n",
    "    \n",
    "    if len(it1)+len(it2) != 2:\n",
    "        print(row['id'])\n",
    "    \n",
    "    if len(dataset[dataset['id'] == sid]) == 0:\n",
    "        better_count = 1 if 'BETTER' in row['label'] else 0\n",
    "        worse_count = 1 if 'WORSE' in row['label'] else 0\n",
    "        none_count = 1 if 'NONE' in row['label'] else 0\n",
    "        none_count = 1 if 'OTHER' in row['label'] else 0\n",
    "        most_frequent_class = '-'\n",
    "        most_frequent_class_percentage = 0\n",
    "        total_judgements = 1\n",
    "        it1_judgments = it1.iloc[0]['_trusted_judgments']\n",
    "        it1_confidence = it1.iloc[0]['iteration_1_confidence']\n",
    "        it2_judgments = it2.iloc[0]['_trusted_judgments']\n",
    "        it2_confidence = it2.iloc[0]['iteration_1_confidence']\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "print('{} {}'.format(len(full['id'].unique()),len(aggregated['id'].unique())))\n",
    "aggregated.rename(columns={\"label\":\"old_label\"})\n",
    "aggregated['better_count'] = 0\n",
    "aggregated['worse_count'] = 0\n",
    "aggregated['none_count'] = 0\n",
    "aggregated['judgements'] = 0\n",
    "aggregated['label_winner_count'] = 0\n",
    "aggregated['judgements_it_1'] = 0\n",
    "aggregated['judgements_it_2'] = 0\n",
    "aggregated['most_frequent_class'] = ''\n",
    "\n",
    "rnd_cnt = 0\n",
    "for i, row in full.iterrows():\n",
    "    try:\n",
    "        r_id = row['id']\n",
    "\n",
    "        col = row['label'].lower() + '_count'\n",
    "        if col == 'other_count':\n",
    "            col = 'none_count'\n",
    "        \n",
    "        if row['iteration'] == 1:\n",
    "            aggregated.loc[aggregated['id'] == r_id, 'confidence_it_1']  aggregated['iteration_1_confidence'].value\n",
    "            aggregated.loc[aggregated['id'] == r_id, 'judgements_it_1'] +=1\n",
    "        else:\n",
    "            #aggregated.loc[aggregated['id'] == r_id, 'confidence_it_2'] = aggregated['iteration_2_confidence'].value\n",
    "            aggregated.loc[aggregated['id'] == r_id, 'judgements_it_2'] +=1\n",
    "            \n",
    "\n",
    "        aggregated.loc[aggregated['id'] == r_id, col] += 1\n",
    "        aggregated.loc[aggregated['id'] == r_id, 'judgements'] += 1\n",
    "        m = [\n",
    "            ('WORSE', aggregated.loc[aggregated['id'] == r_id, 'worse_count'].values[0]),\n",
    "            ('BETTER',  aggregated.loc[aggregated['id'] == r_id, 'better_count'].values[0]),\n",
    "            ('NONE',  aggregated.loc[aggregated['id'] == r_id, 'none_count'].values[0]),\n",
    "        ]\n",
    "        winner = sorted(m,key=lambda k: k[1], reverse=True)\n",
    "        if winner[0][1] == winner[1][1]:\n",
    "            if rnd_cnt % 2 == 0:\n",
    "                aggregated.loc[aggregated['id'] == r_id, 'most_frequent_class'] = winner[0][0]\n",
    "                aggregated.loc[aggregated['id'] == r_id, 'most_frequent_count'] = winner[0][1]\n",
    "            else:\n",
    "                aggregated.loc[aggregated['id'] == r_id, 'most_frequent_class'] = winner[1][0]\n",
    "                aggregated.loc[aggregated['id'] == r_id, 'most_frequent_count'] = winner[1][1]\n",
    "            rnd_cnt += 1\n",
    "                \n",
    "        else:\n",
    "            aggregated.loc[aggregated['id'] == r_id, 'most_frequent_class'] = winner[0][0]\n",
    "            aggregated.loc[aggregated['id'] == r_id, 'most_frequent_count'] = winner[0][1]\n",
    "    except Exception as e:\n",
    "        print(r_id, e)\n",
    "        \n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = aggregated.drop_duplicates(subset=['id'])\n",
    "\n",
    "\n",
    "print('{} - without dups: {}'.format(len(aggregated),len(dd)))\n",
    "\n",
    "# note: duplicates exist from the merge of the two rows (both rows still present)\n",
    "\n",
    "dd['ratio'] =  dd['most_frequent_count']/dd['judgements']\n",
    "certain = dd[dd['ratio'] > 0.5 ]\n",
    "print('All: {} Certain: {}'.format(len(dd), len(dd[dd['ratio'] > 0.5 ])))\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "dd.sort_values('judgements')\n",
    "dd['judgements'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = certain[['id','text_html', 'text_readable', 'label:confidence', 'label']]\n",
    "display(conf[['label:confidence']].describe())\n",
    "display(conf[['id', 'text_html']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import operator\n",
    "d = defaultdict(int)\n",
    "exp = r'[\\w\\s+*-]+(?=:\\[OBJECT_[AB]\\])'\n",
    "s = set()\n",
    "for i, row in certain.iterrows():\n",
    "    a = (sorted(re.findall(exp, row['text_html'])))\n",
    "    d['{} vs. {}'.format(a[0],a[1])] += 1\n",
    "print(len(d))\n",
    "pprint(sorted(d.items(), key=operator.itemgetter(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        return '{p:.2f}%  ({v:d})'.format(p=pct,v=val)\n",
    "    return my_autopct\n",
    "\n",
    "def show_dist(labels):\n",
    "\n",
    "    plt.figure(figsize=plt.figaspect(1))\n",
    "    plt.pie(\n",
    "        labels.value_counts().values,\n",
    "        labels=labels.value_counts().keys().tolist(),\n",
    "        radius=2,\n",
    "        autopct=make_autopct(labels.value_counts().values))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_dist(certain['most_frequent_class'])\n",
    "show_dist(dd['most_frequent_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_i, test_i = train_test_split(dd,stratify=dd['most_frequent_class'], test_size=0.2,random_state=42)\n",
    "print('{} {} {}'.format(len(train_i), len(test_i), (len(train_i)+ len(test_i))))\n",
    "train_i.to_csv('data.csv')\n",
    "test_i.to_csv('dev-data.csv')\n",
    "print(train_i['_golden'].unique())\n",
    "print(test_i['_golden'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd[['judgements']].sort_values('judgements')['judgements'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd[['ratio']].sort_values('ratio')['ratio'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('More than 50% {} | Less {}'.format(len(dd[dd['ratio'] >= 0.5]),len(dd[dd['ratio'] <= 0.5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dd[~(dd['label'] == dd['most_frequent_class'])][['type','a','b', 'raw_text', 'better_count', 'worse_count', 'none_count', 'judgements', 'label','most_frequent_class']]\n",
    "a.sort_values('judgements',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
